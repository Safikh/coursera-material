{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N22NDjIjjxcI"
   },
   "source": [
    "# Distributed Training with GPUs on Cloud AI Platform\n",
    "\n",
    "**Learning Objectives:**\n",
    "  1. Setting up the environment\n",
    "  1. Create a model to train locally\n",
    "  1. Train on multiple GPUs/CPUs with MultiWorkerMirrored Strategy\n",
    "\n",
    "In this notebook, we will walk through using Cloud AI Platform to perform distributed training using the `MirroredStrategy` found within `tf.keras`. This strategy will allow us to use the synchronous AllReduce strategy on a VM with multiple GPUs attached.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [Solution Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/production_ml/solutions/distributed_training.ipynb) for reference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nny3m465gKkY"
   },
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63e-3SdLlh7K"
   },
   "source": [
    "Next we will configure our environment. Be sure to change the `PROJECT_ID` variable in the below cell to your Project ID. This will be the project to which the Cloud AI Platform resources will be billed. We will also create a bucket for our training artifacts (if it does not already exist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task #1: Setting up the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "TKZYJbBkBcOk",
    "outputId": "8dac5564-c864-4db8-9cc2-0c8036b75eb8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# TODO 1\n",
    "PROJECT_ID = \"qwiklabs-gcp-04-bc5e75cdd85e\"  # Replace with your PROJECT\n",
    "BUCKET = PROJECT_ID \n",
    "REGION = 'us-central1'\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"BUCKET\"] = BUCKET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jth9W8NtmNUD"
   },
   "source": [
    "Since we are going to submit our training job to Cloud AI Platform, we need to create our trainer package. We will create the `train` directory for our package and create a blank `__init__.py` file so Python knows that this folder contains a package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cavM78bf_mU4"
   },
   "outputs": [],
   "source": [
    "!mkdir train\n",
    "!touch train/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIMQo_lImhn_"
   },
   "source": [
    "Next we will create a module containing a function which will create our model. Note that we will be using the Fashion MNIST dataset. Since it's a small dataset, we will simply load it into memory for getting the parameters for our model.\n",
    "\n",
    "Our model will be a DNN with only dense layers, applying dropout to each hidden layer. We will also use ReLU activation for all hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "88-9WeCQ_mU9",
    "outputId": "ae92afd1-93bd-49e5-aeda-6f6e177ac186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/model_definition.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/model_definition.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Get data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# add empty color dimension\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=x_train.shape[1:]))\n",
    "    model.add(tf.keras.layers.Dense(1028))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(512))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    model.add(tf.keras.layers.Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DOKsnDhnU87"
   },
   "source": [
    "Before we submit our training jobs to Cloud AI Platform, let's be sure our model runs locally. We will call the `model_definition` function to create our model and use `tf.keras.datasets.fashion_mnist.load_data()` to import the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task #2: Create a model to train locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "r8bPcX7T-SH1",
    "outputId": "1069992b-0599-4b19-f7e8-b4cefa7cb6bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 16:37:04.840921: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 125s 518ms/step - loss: 4.7914 - sparse_categorical_accuracy: 0.6299 - val_loss: 0.6253 - val_sparse_categorical_accuracy: 0.8002\n",
      "Training time without GPUs locally: 124.96035313606262\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from train import model_definition\n",
    "\n",
    "#Get data\n",
    "\n",
    "# TODO 2\n",
    "# TODO -- Your code here.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "def create_dataset(X, y, epochs, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "ds_train = create_dataset(x_train, y_train, 20, 5000)\n",
    "ds_test = create_dataset(x_test, y_test, 1, 1000)\n",
    "\n",
    "model = model_definition.create_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "start = time.time()\n",
    "model.fit(ds_train, validation_data=ds_test, verbose=1)\n",
    "print(\"Training time without GPUs locally: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_U-u_tZ_mVK"
   },
   "source": [
    "\n",
    "\n",
    "## Train on multiple GPUs/CPUs with MultiWorkerMirrored Strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0VQ7GUsn8wb"
   },
   "source": [
    "That took a few minutes to train our model for 20 epochs. Let's see how we can do better using Cloud AI Platform. We will be leveraging the `MultiWorkerMirroredStrategy` supplied in `tf.distribute`. The main difference between this code and the code from the local test is that we need to compile the model within the scope of the strategy. When we do this our training op will use information stored in the `TF_CONFIG` variable to assign ops to the various devices for the AllReduce strategy. \n",
    "\n",
    "After the training process finishes, we will print out the time spent training. Since it takes a few minutes to spin up the resources being used for training on Cloud AI Platform, and this time can vary, we want a consistent measure of how long training took.\n",
    "\n",
    "Note: When we train models on Cloud AI Platform, the `TF_CONFIG` variable is automatically set. So we do not need to worry about adjusting based on what cluster configuration we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_AF4VDhT_mVg",
    "outputId": "e2e1a496-a369-4f62-856a-b2fe88178add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/train_mult_worker_mirrored.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/train_mult_worker_mirrored.py\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from . import model_definition\n",
    "\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "#Get data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# add empty color dimension\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "def create_dataset(X, Y, epochs, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "ds_train = create_dataset(x_train, y_train, 20, 5000)\n",
    "ds_test = create_dataset(x_test, y_test, 1, 1000)\n",
    "\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    model = model_definition.create_model()\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['sparse_categorical_accuracy'])\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_test, \n",
    "    verbose=2\n",
    ")\n",
    "print(\"Training time with multiple GPUs: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task #3: Training with multiple GPUs/CPUs on created model using MultiWorkerMirrored Strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViUZcz7Tp9Kp"
   },
   "source": [
    "First we will train a model without using GPUs to give us a baseline. We will use a consistent format throughout the trials. We will define a `config.yaml` file to contain our cluster configuration and the pass this file in as the value of a command-line argument `--config`.\n",
    "\n",
    "In our first example, we will use a single `n1-highcpu-16` VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "sBJw5hJAadVW",
    "outputId": "8f377e27-e1c3-4a44-e5ef-21c37a7f64fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "# TODO 3a\n",
    "# TODO -- Your code here.\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: n1-highcpu-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "_mlylgvCaeXW",
    "outputId": "383eb016-e791-4cfc-f382-72acd47932b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: cpu_only_fashion_minst_20220819_170438\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [cpu_only_fashion_minst_20220819_170438] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe cpu_only_fashion_minst_20220819_170438\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs cpu_only_fashion_minst_20220819_170438\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"cpu_only_fashion_minst_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_mult_worker_mirrored \\\n",
    "  --runtime-version=2.3 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-west1 \\\n",
    "  --config config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9tji3XRqbi-"
   },
   "source": [
    "If we go through the logs, we see that the training job will take around 5-7 minutes to complete. Let's now attach two Nvidia Tesla K80 GPUs and rerun the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2022-08-19 17:04:40 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2022-08-19 17:04:40 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2022-08-19 17:04:40 +0000\tservice\t\tJob cpu_only_fashion_minst_20220819_170438 is queued.\n",
      "INFO\t2022-08-19 17:04:41 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2022-08-19 17:04:44 +0000\tservice\t\tWaiting for training program to start.\n",
      "NOTICE\t2022-08-19 17:05:32 +0000\tmaster-replica-0.gcsfuse\t\tOpening GCS connection...\n",
      "NOTICE\t2022-08-19 17:05:32 +0000\tmaster-replica-0.gcsfuse\t\tMounting file system \"gcsfuse\"...\n",
      "NOTICE\t2022-08-19 17:05:32 +0000\tmaster-replica-0.gcsfuse\t\tFile system has been successfully mounted.\n",
      "INFO\t2022-08-19 17:07:12 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"chief\": [\"127.0.0.1:2222\"]} --task={\"type\": \"chief\", \"index\": 0} --job={  \"scale_tier\": \"CUSTOM\",  \"master_type\": \"n1-highcpu-16\",  \"package_uris\": [\"gs://qwiklabs-gcp-04-bc5e75cdd85e/cpu_only_fashion_minst_20220819_170438/a6ac4c3f67e6f49d0057c1b9f0ac28325d8a37761fcdc8e46ccfdedf25b366ed/train-0.0.0.tar.gz\"],  \"python_module\": \"train.train_mult_worker_mirrored\",  \"region\": \"us-west1\",  \"runtime_version\": \"2.3\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.7\"}\n",
      "INFO\t2022-08-19 17:07:20 +0000\tmaster-replica-0\t\tRunning module train.train_mult_worker_mirrored.\n",
      "INFO\t2022-08-19 17:07:20 +0000\tmaster-replica-0\t\tDownloading the package: gs://qwiklabs-gcp-04-bc5e75cdd85e/cpu_only_fashion_minst_20220819_170438/a6ac4c3f67e6f49d0057c1b9f0ac28325d8a37761fcdc8e46ccfdedf25b366ed/train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:07:20 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://qwiklabs-gcp-04-bc5e75cdd85e/cpu_only_fashion_minst_20220819_170438/a6ac4c3f67e6f49d0057c1b9f0ac28325d8a37761fcdc8e46ccfdedf25b366ed/train-0.0.0.tar.gz train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:07:21 +0000\tmaster-replica-0\t\tInstalling the package: gs://qwiklabs-gcp-04-bc5e75cdd85e/cpu_only_fashion_minst_20220819_170438/a6ac4c3f67e6f49d0057c1b9f0ac28325d8a37761fcdc8e46ccfdedf25b366ed/train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:07:21 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:07:21 +0000\tmaster-replica-0\t\tProcessing ./train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:07:22 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: train\n",
      "INFO\t2022-08-19 17:07:22 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): started\n",
      "INFO\t2022-08-19 17:07:22 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): finished with status 'done'\n",
      "INFO\t2022-08-19 17:07:22 +0000\tmaster-replica-0\t\t  Created wheel for train: filename=train-0.0.0-py3-none-any.whl size=2400 sha256=b711ea941f6a0314ca190110fbd513dfb757bb3093409da85ee79be1ab77c160\n",
      "INFO\t2022-08-19 17:07:22 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/eb/9e/12/ea651dac6f91cb6a4acd3a0bbca894502dd99c2e4e2f6a5abf\n",
      "INFO\t2022-08-19 17:07:23 +0000\tmaster-replica-0\t\tSuccessfully built train\n",
      "INFO\t2022-08-19 17:07:23 +0000\tmaster-replica-0\t\tInstalling collected packages: train\n",
      "INFO\t2022-08-19 17:07:23 +0000\tmaster-replica-0\t\tSuccessfully installed train-0.0.0\n",
      "ERROR\t2022-08-19 17:07:23 +0000\tmaster-replica-0\t\tWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "INFO\t2022-08-19 17:07:23 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:07:23 +0000\tmaster-replica-0\t\tProcessing ./train-0.0.0.tar.gz\n",
      "ERROR\t2022-08-19 17:07:24 +0000\tmaster-replica-0\t\tDEPRECATION: Source distribution is being reinstalled despite an installed package having the same name and version as the installed package. pip 21.2 will remove support for this functionality. A possible replacement is use --force-reinstall. You can find discussion regarding this at https://github.com/pypa/pip/issues/8711.\n",
      "INFO\t2022-08-19 17:07:24 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: train\n",
      "INFO\t2022-08-19 17:07:24 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): started\n",
      "INFO\t2022-08-19 17:07:25 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): finished with status 'done'\n",
      "INFO\t2022-08-19 17:07:25 +0000\tmaster-replica-0\t\t  Created wheel for train: filename=train-0.0.0-py3-none-any.whl size=2400 sha256=9d03090bb642c2d23867bad7ba87ca77f4f73c63b4d34d463065f39f33b558da\n",
      "INFO\t2022-08-19 17:07:25 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/eb/9e/12/ea651dac6f91cb6a4acd3a0bbca894502dd99c2e4e2f6a5abf\n",
      "INFO\t2022-08-19 17:07:25 +0000\tmaster-replica-0\t\tSuccessfully built train\n",
      "INFO\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\tInstalling collected packages: train\n",
      "INFO\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\t  Attempting uninstall: train\n",
      "INFO\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\t    Found existing installation: train 0.0.0\n",
      "INFO\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\t    Uninstalling train-0.0.0:\n",
      "INFO\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\t      Successfully uninstalled train-0.0.0\n",
      "INFO\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\tSuccessfully installed train-0.0.0\n",
      "ERROR\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\tWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "INFO\t2022-08-19 17:07:27 +0000\tmaster-replica-0\t\tRunning command: python3 -m train.train_mult_worker_mirrored\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t 8192/29515 [=======>......................] - ETA: \n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t32768/29515 [=================================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t    8192/26421880 [..............................] - ETA: \n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t 4202496/26421880 [===>..........................] - ETA: \n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t 8396800/26421880 [========>.....................] - ETA: \n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t19030016/26421880 [====================>.........] - ETA: \n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t26427392/26421880 [==============================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t8192/5148 [===============================================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t   8192/4422102 [..............................] - ETA: \n",
      "INFO\t2022-08-19 17:07:30 +0000\tmaster-replica-0\t\t4423680/4422102 [==============================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\tCPU Frequency: 2199995000 Hz\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\tXLA service 0x5650125a01e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\t  StreamExecutor device (0): Host, Default Version\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\tInitialize GrpcChannelCache for job chief -> {0 -> 127.0.0.1:2222}\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\tStarted server with target: grpc://127.0.0.1:2222\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\tEnabled multi-worker collective ops with available devices: ['/job:chief/replica:0/task:0/device:CPU:0', '/job:chief/replica:0/task:0/device:XLA_CPU:0']\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\tUsing MirroredStrategy with devices ('/job:chief/task:0',)\n",
      "INFO\t2022-08-19 17:07:31 +0000\tmaster-replica-0\t\tMultiWorkerMirroredStrategy with cluster_spec = {'chief': ['127.0.0.1:2222']}, task_type = 'chief', task_id = 0, num_workers = 1, local_devices = ('/job:chief/task:0',), communication = CollectiveCommunication.AUTO\n",
      "INFO\t2022-08-19 17:07:59 +0000\tmaster-replica-0\t\tNumber of devices: 1\n",
      "INFO\t2022-08-19 17:07:59 +0000\tmaster-replica-0\t\t240/240 - 24s - loss: 4.6577 - sparse_categorical_accuracy: 0.6378 - val_loss: 0.6002 - val_sparse_categorical_accuracy: 0.7980\n",
      "INFO\t2022-08-19 17:07:59 +0000\tmaster-replica-0\t\tTraining time with multiple GPUs: 27.321717023849487\n",
      "INFO\t2022-08-19 17:07:59 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2022-08-19 17:07:59 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2022-08-19 17:07:59 +0000\tmaster-replica-0\t\tTask completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs stream-logs cpu_only_fashion_minst_20220819_170438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fCGWARBH_mVi",
    "outputId": "64f42735-7356-40c4-8460-afc096a9896c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "# TODO 3b\n",
    "# TODO -- Your code here.\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: n1-highcpu-16\n",
    "  masterConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 2\n",
    "      type: NVIDIA_TESLA_K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "UmXeeg6r_mVk",
    "outputId": "0017abd4-077d-4089-f664-d15dac69f755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: multi_gpu_fashion_minst_2gpu_20220819_171323\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [multi_gpu_fashion_minst_2gpu_20220819_171323] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe multi_gpu_fashion_minst_2gpu_20220819_171323\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs multi_gpu_fashion_minst_2gpu_20220819_171323\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"multi_gpu_fashion_minst_2gpu_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_mult_worker_mirrored \\\n",
    "  --runtime-version=2.3 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-west1 \\\n",
    "  --config config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fMLxLOgq7mc"
   },
   "source": [
    "That was a lot faster! The training job will take upto 5-10 minutes to complete. Let's keep going and add more GPUs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2022-08-19 17:13:24 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2022-08-19 17:13:24 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2022-08-19 17:13:24 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2022-08-19 17:13:24 +0000\tservice\t\tJob multi_gpu_fashion_minst_2gpu_20220819_171323 is queued.\n",
      "INFO\t2022-08-19 17:13:26 +0000\tservice\t\tWaiting for training program to start.\n",
      "NOTICE\t2022-08-19 17:14:34 +0000\tmaster-replica-0.gcsfuse\t\tOpening GCS connection...\n",
      "NOTICE\t2022-08-19 17:14:34 +0000\tmaster-replica-0.gcsfuse\t\tMounting file system \"gcsfuse\"...\n",
      "NOTICE\t2022-08-19 17:14:34 +0000\tmaster-replica-0.gcsfuse\t\tFile system has been successfully mounted.\n",
      "INFO\t2022-08-19 17:17:36 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"chief\": [\"127.0.0.1:2222\"]} --task={\"type\": \"chief\", \"index\": 0} --job={  \"scale_tier\": \"CUSTOM\",  \"master_type\": \"n1-highcpu-16\",  \"package_uris\": [\"gs://qwiklabs-gcp-04-bc5e75cdd85e/multi_gpu_fashion_minst_2gpu_20220819_171323/24b47efc43899e9a3b85f120fa54a355afa572b6cb79ab1e88373152c26b4cc4/train-0.0.0.tar.gz\"],  \"python_module\": \"train.train_mult_worker_mirrored\",  \"region\": \"us-west1\",  \"runtime_version\": \"2.3\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.7\",  \"master_config\": {    \"accelerator_config\": {      \"count\": \"2\",      \"type\": \"NVIDIA_TESLA_K80\"    }  }}\n",
      "INFO\t2022-08-19 17:17:42 +0000\tmaster-replica-0\t\tRunning module train.train_mult_worker_mirrored.\n",
      "INFO\t2022-08-19 17:17:42 +0000\tmaster-replica-0\t\tDownloading the package: gs://qwiklabs-gcp-04-bc5e75cdd85e/multi_gpu_fashion_minst_2gpu_20220819_171323/24b47efc43899e9a3b85f120fa54a355afa572b6cb79ab1e88373152c26b4cc4/train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:17:42 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://qwiklabs-gcp-04-bc5e75cdd85e/multi_gpu_fashion_minst_2gpu_20220819_171323/24b47efc43899e9a3b85f120fa54a355afa572b6cb79ab1e88373152c26b4cc4/train-0.0.0.tar.gz train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:17:43 +0000\tmaster-replica-0\t\tInstalling the package: gs://qwiklabs-gcp-04-bc5e75cdd85e/multi_gpu_fashion_minst_2gpu_20220819_171323/24b47efc43899e9a3b85f120fa54a355afa572b6cb79ab1e88373152c26b4cc4/train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:17:43 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:17:44 +0000\tmaster-replica-0\t\tProcessing ./train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:17:44 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: train\n",
      "INFO\t2022-08-19 17:17:44 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): started\n",
      "INFO\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): finished with status 'done'\n",
      "INFO\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\t  Created wheel for train: filename=train-0.0.0-py3-none-any.whl size=2400 sha256=b2bcd8a7facb83e5095898b9871d84a62304c7fab97e70b4f7d27918cc051bea\n",
      "INFO\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/eb/9e/12/ea651dac6f91cb6a4acd3a0bbca894502dd99c2e4e2f6a5abf\n",
      "INFO\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\tSuccessfully built train\n",
      "INFO\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\tInstalling collected packages: train\n",
      "INFO\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\tSuccessfully installed train-0.0.0\n",
      "ERROR\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\tWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "INFO\t2022-08-19 17:17:45 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user train-0.0.0.tar.gz\n",
      "INFO\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\tProcessing ./train-0.0.0.tar.gz\n",
      "ERROR\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\tDEPRECATION: Source distribution is being reinstalled despite an installed package having the same name and version as the installed package. pip 21.2 will remove support for this functionality. A possible replacement is use --force-reinstall. You can find discussion regarding this at https://github.com/pypa/pip/issues/8711.\n",
      "INFO\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: train\n",
      "INFO\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): started\n",
      "INFO\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\t  Building wheel for train (setup.py): finished with status 'done'\n",
      "INFO\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\t  Created wheel for train: filename=train-0.0.0-py3-none-any.whl size=2400 sha256=d7c295a9f7500d53590476f0669f04b7e9b2e5f7cfcc62b937c76047b7dfd035\n",
      "INFO\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/eb/9e/12/ea651dac6f91cb6a4acd3a0bbca894502dd99c2e4e2f6a5abf\n",
      "INFO\t2022-08-19 17:17:46 +0000\tmaster-replica-0\t\tSuccessfully built train\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\tInstalling collected packages: train\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\t  Attempting uninstall: train\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\t    Found existing installation: train 0.0.0\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\t    Uninstalling train-0.0.0:\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\t      Successfully uninstalled train-0.0.0\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\tSuccessfully installed train-0.0.0\n",
      "ERROR\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\tWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\tRunning command: python3 -m train.train_mult_worker_mirrored\n",
      "INFO\t2022-08-19 17:17:48 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudart.so.11.0\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t 8192/29515 [=======>......................] - ETA: \n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t32768/29515 [=================================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t    8192/26421880 [..............................] - ETA: \n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t 4202496/26421880 [===>..........................] - ETA: \n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t13983744/26421880 [==============>...............] - ETA: \n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t24043520/26421880 [==========================>...] - ETA: \n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t26427392/26421880 [==============================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t8192/5148 [===============================================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t   8192/4422102 [..............................] - ETA: \n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t2105344/4422102 [=============>................] - ETA: \n",
      "INFO\t2022-08-19 17:17:51 +0000\tmaster-replica-0\t\t4423680/4422102 [==============================] - 0s 0us/step\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcuda.so.1\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tFound device 0 with properties: \n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tpciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tcoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tFound device 1 with properties: \n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tpciBusID: 0000:00:05.0 name: Tesla K80 computeCapability: 3.7\n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tcoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudart.so.11.0\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcublas.so.11\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcufft.so.10\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcurand.so.10\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcusolver.so.10\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcusparse.so.11\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudnn.so.8\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tAdding visible gpu devices: 0, 1\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tCPU Frequency: 2199995000 Hz\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tXLA service 0x5633345e3cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\t  StreamExecutor device (0): Host, Default Version\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tXLA service 0x563337099370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\t  StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\t  StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tFound device 0 with properties: \n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tpciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tcoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tFound device 1 with properties: \n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tpciBusID: 0000:00:05.0 name: Tesla K80 computeCapability: 3.7\n",
      "ERROR\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tcoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudart.so.11.0\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcublas.so.11\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcufft.so.10\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcurand.so.10\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcusolver.so.10\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcusparse.so.11\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudnn.so.8\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tAdding visible gpu devices: 0, 1\n",
      "INFO\t2022-08-19 17:17:52 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudart.so.11.0\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tDevice interconnect StreamExecutor with strength 1 edge matrix:\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\t     0 1 \n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\t0:   N Y \n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\t1:   Y N \n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tCreated TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10638 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tCreated TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10638 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tFound device 0 with properties: \n",
      "ERROR\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tpciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "ERROR\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tcoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tFound device 1 with properties: \n",
      "ERROR\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tpciBusID: 0000:00:05.0 name: Tesla K80 computeCapability: 3.7\n",
      "ERROR\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tcoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudart.so.11.0\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcublas.so.11\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcufft.so.10\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcurand.so.10\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcusolver.so.10\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcusparse.so.11\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcudnn.so.8\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tAdding visible gpu devices: 0, 1\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tDevice interconnect StreamExecutor with strength 1 edge matrix:\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\t     0 1 \n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\t0:   N Y \n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\t1:   Y N \n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tCreated TensorFlow device (/job:chief/replica:0/task:0/device:GPU:0 with 10638 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tCreated TensorFlow device (/job:chief/replica:0/task:0/device:GPU:1 with 10638 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tInitialize GrpcChannelCache for job chief -> {0 -> 127.0.0.1:2222}\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tStarted server with target: grpc://127.0.0.1:2222\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tEnabled multi-worker collective ops with available devices: ['/job:chief/replica:0/task:0/device:CPU:0', '/job:chief/replica:0/task:0/device:XLA_CPU:0', '/job:chief/replica:0/task:0/device:XLA_GPU:0', '/job:chief/replica:0/task:0/device:XLA_GPU:1', '/job:chief/replica:0/task:0/device:GPU:0', '/job:chief/replica:0/task:0/device:GPU:1']\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tUsing MirroredStrategy with devices ('/job:chief/task:0/device:GPU:0', '/job:chief/task:0/device:GPU:1')\n",
      "INFO\t2022-08-19 17:17:53 +0000\tmaster-replica-0\t\tMultiWorkerMirroredStrategy with cluster_spec = {'chief': ['127.0.0.1:2222']}, task_type = 'chief', task_id = 0, num_workers = 1, local_devices = ('/job:chief/task:0/device:GPU:0', '/job:chief/task:0/device:GPU:1'), communication = CollectiveCommunication.AUTO\n",
      "INFO\t2022-08-19 17:17:54 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 8 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:54 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:54 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:54 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:54 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:56 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 8 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:56 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:56 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:56 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:56 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:17:57 +0000\tmaster-replica-0\t\tSuccessfully opened dynamic library libcublas.so.11\n",
      "INFO\t2022-08-19 17:18:02 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:18:02 +0000\tmaster-replica-0\t\tCollective batch_all_reduce: 1 all-reduces, num_devices = 2, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO\t2022-08-19 17:18:04 +0000\tmaster-replica-0\t\tNumber of devices: 2\n",
      "INFO\t2022-08-19 17:18:04 +0000\tmaster-replica-0\t\t240/240 - 6s - loss: 4.3179 - sparse_categorical_accuracy: 0.6310 - val_loss: 0.6685 - val_sparse_categorical_accuracy: 0.7718\n",
      "INFO\t2022-08-19 17:18:04 +0000\tmaster-replica-0\t\tTraining time with multiple GPUs: 10.128752946853638\n",
      "INFO\t2022-08-19 17:18:06 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2022-08-19 17:18:06 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2022-08-19 17:18:06 +0000\tmaster-replica-0\t\tTask completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs stream-logs multi_gpu_fashion_minst_2gpu_20220819_171323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ocXYk61hGRG_",
    "outputId": "ff6d1dc4-ab02-4ab7-acea-2420c5c1d5aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "# TODO 3c\n",
    "# TODO -- Your code here.\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: n1-highcpu-16\n",
    "  masterConfig:\n",
    "    acceleratorConfig:\n",
    "      count: 4\n",
    "      type: NVIDIA_TESLA_K80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "MKRRVDLhZoj3",
    "outputId": "4012bb48-d7f9-4e6b-d034-daa258cc636f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: multi_gpu_fashion_minst_4gpu_20220819_172344\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [multi_gpu_fashion_minst_4gpu_20220819_172344] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe multi_gpu_fashion_minst_4gpu_20220819_172344\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs multi_gpu_fashion_minst_4gpu_20220819_172344\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"multi_gpu_fashion_minst_4gpu_$now\"\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --package-path=train \\\n",
    "  --module-name=train.train_mult_worker_mirrored \\\n",
    "  --runtime-version=2.3 \\\n",
    "  --python-version=3.7 \\\n",
    "  --region=us-west1 \\\n",
    "  --config config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3PfreD5rfgE"
   },
   "source": [
    "The training job will take upto 10 minutes to complete. It was faster than no GPUs, but why was it slower than 2 GPUs? If you rerun this job with 8 GPUs you'll actually see it takes just as long as using no GPUs!\n",
    "\n",
    "The answer is in our input pipeline. In short, the I/O involved in using more GPUs started to outweigh the benefits of having more available devices. We can try to improve our input pipelines to overcome this (e.g. using caching, adjusting batch size, etc.). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Multi-GPU Training on CAIP",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
